# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CkWobTGb9U-TV3GCPvtoJDLiOvvu9Jcp
"""

import numpy as np
import pandas as pd

data = pd.read_csv('/SAHeart.csv', sep=',') #buscando df no caminho
data #exibindo df

data.info() #puxando informações do df

data.duplicated().any() #checando se tem duplicatas

data.hist(bins=60,figsize=(20,16)) #Plotar graficos de frequencias de cada coluna



data.drop(columns='row.names',inplace=True) #removendo a coluna row.names do df
data

# Substituindo os valores na coluna 'famhist' sendo 1 para present e 0 para absent a fim de facilitar analise e trabalhar apenas com numeros
data['famhist'] = data['famhist'].replace({'Present': 1, 'Absent': 0})
data

import matplotlib.pyplot as plt

# Extrair os dados de "age" e "obesity" do DataFrame e exibindo em função dos dois
age = data['age']
obesity = data['obesity']

# Plotar o gráfico de dispersão
plt.figure(figsize=(8, 6))
plt.scatter(obesity, age, color='blue', alpha=0.5)
plt.title('Idade vs Obesidade')
plt.xlabel('Obesidade')
plt.ylabel('Idade')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Filtrar os dados para valores de "obesity" maiores ou iguais a 30
data_filtered = data[data['obesity'] >= 30]

# Extrair os dados de "age" e "obesity" do DataFrame filtrado
age_filtered = data_filtered['age']
obesity_filtered = data_filtered['obesity']

# Plotar o gráfico de dispersão
plt.figure(figsize=(8, 6))
plt.scatter(obesity_filtered, age_filtered, color='blue', alpha=0.5)
plt.title('Age for Obesity >= 30')
plt.xlabel('Obesity')
plt.ylabel('Age')
plt.grid(True)
plt.show()

#realizando contagem de ocorrências de cada valor na coluna "famhist, a fim de saber quantos % temos de cada um
famhist_counts = data['famhist'].value_counts(normalize=True) * 100

# Plotar o gráfico de barras
plt.figure(figsize=(6, 4))
famhist_counts.plot(kind='bar', color='blue', alpha=0.7)
plt.title('Porcentagem de valores de famhist')
plt.xlabel('famhist')
plt.ylabel('Percentage')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Imprimir os valores
print("Porcentagem de '1' na coluna 'famhist':", famhist_counts[1])
print("Porcentagem de '0' na coluna 'famhist':", famhist_counts[0])

import matplotlib.pyplot as plt

#checando se há pessoas menores de 18 anos que ingerem alcool
age = data['age']
alcohol = data['alcohol']

# Plotar o gráfico de dispersão
plt.figure(figsize=(8, 6))
plt.scatter(age, alcohol, color='blue', alpha=0.5)
plt.title('Age vs Alcohol')
plt.xlabel('Age')
plt.ylabel('Alcohol')
plt.grid(True)
plt.show()

# Verificar se existem dados na coluna "alcohol" onde a coluna "age" é menor que 18
# e a coluna "alcohol" é maior que 0
underage_and_positive_alcohol = data[(data['age'] < 18) & (data['alcohol'] > 0)]['alcohol']

if underage_and_positive_alcohol.empty:
    print("Não há dados na coluna 'alcohol' onde a coluna 'age' é menor que 18 e 'alcohol' é maior que 0.")
else:
    print("Existem dados na coluna 'alcohol' onde a coluna 'age' é menor que 18 e 'alcohol' é maior que 0:")
    print(underage_and_positive_alcohol)

X=data.copy() #criando uma copia do df chamada X
y=X.pop('chd') #definindo y como x sem a coluna "chd"
X

#Os codigos anteriores, eram referentes a tratamento de dados conforme a primeira unidade.
#Agora partiremos para segunda unidade, onde exploramos ferramentas de Machine Learning


#Essa parte do código fará uma divisão dos dados em conjuntos de treinamento e teste usando a função train_test_split do scikit-learn (sklearn)

from sklearn.model_selection import train_test_split #importando a funcao
#agora dividindo os dados em conjunto de treinamento e teste:

X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8)
#x é o conjunto de features e y o conjunto de rotulos.
#o train_size especifica a porcentagem de dados que serao usados para treinamento (80%), restando 20% para teste.

#no codigo abaixo, aplicaremos duas técnicas de pré-processamento de dados aos conjuntos de treinamento e teste.
#utilizaremos as classes StandardScaler e MinMaxScaler do scikit-learn (sklearn).

from sklearn.preprocessing import StandardScaler, MinMaxScaler #importando as classes

scale_columns = [col for col in X.columns if col!='famhist'] #definindo as colunas escaladas, excluindo "famhist"
scaler = StandardScaler() #objeto standscaler
min_max_scaler = MinMaxScaler() #objeto minmaxscaler

X_train[scale_columns] = scaler.fit_transform(X_train[scale_columns]) #padronizando colunas de train com standscaler
X_test[scale_columns] = scaler.transform(X_test[scale_columns]) #padronizando colunas de test com standscaler

#agora aplica a escala min-max (normalização) às mesmas colunas, tanto nos conjuntos de train quanto nos test, usando MinMaxScaler
X_train[scale_columns] = min_max_scaler.fit_transform(X_train[scale_columns])
X_test[scale_columns] = min_max_scaler.transform(X_test[scale_columns])

#pronto. uma vez realizados os treinamentos e testes, partiremos para os algoritmos

#primeiro algoritmo:
#Modelo de Regressão Logística

#importando classes
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score,roc_auc_score,accuracy_score,precision_score,recall_score
#comecando um modelo de regressao logistica, com iteracao maxima de 300
LG_model = LogisticRegression(max_iter=300)
#usando conjunto de treinamentos x e y
LG_model.fit(X_train,y_train)
#fazendo previsoes usando modelo treinado no conjunto de testes
y_pred_lr = LG_model.predict(X_test)

#AVALIACAO DO DESEMPENHO DO MODELO DE ACORDO COM METRICAS
print('accuracy score : ',accuracy_score(y_pred_lr,y_test))
print('precision_score : ',precision_score(y_pred_lr,y_test))
print('recall score : ',recall_score(y_pred_lr,y_test))
print('f1_score : ',f1_score(y_pred_lr,y_test))
print('roc_auc_score : ',roc_auc_score(y_pred_lr,y_test))

#segundo algoritmo: Random Forest
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier()
rf_model.fit(X_train,y_train)
y_pred_rf = rf_model.predict(X_test)
print('accuracy score : ',accuracy_score(y_pred_rf,y_test))
print('precision_score : ',precision_score(y_pred_rf,y_test))
print('recall score : ',recall_score(y_pred_rf,y_test))
print('f1_score : ',f1_score(y_pred_rf,y_test))
print('roc_auc_score : ',roc_auc_score(y_pred_rf,y_test))

#terceiro algoritmo: K-NN
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)
y_pred_knn = knn_model.predict(X_test)
print('accuracy score : ',accuracy_score(y_pred_knn,y_test))
print('precision_score : ',precision_score(y_pred_knn,y_test))
print('recall score : ',recall_score(y_pred_knn,y_test))
print('f1_score : ',f1_score(y_pred_knn,y_test))
print('roc_auc_score : ',roc_auc_score(y_pred_knn,y_test))

#Agora, a partir dos dados obtidos, gerarei graficos

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

# Resultados da Regressão Logística
accuracy_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr)
recall_lr = recall_score(y_test, y_pred_lr)
f1_lr = f1_score(y_test, y_pred_lr)
roc_auc_lr = roc_auc_score(y_test, y_pred_lr)

# Resultados do Random Forest
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)
roc_auc_rf = roc_auc_score(y_test, y_pred_rf)

# Resultados do K-NN
accuracy_knn = accuracy_score(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn)
recall_knn = recall_score(y_test, y_pred_knn)
f1_knn = f1_score(y_test, y_pred_knn)
roc_auc_knn = roc_auc_score(y_test, y_pred_knn)

# Métricas
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC Score']
lr_metrics = [accuracy_lr, precision_lr, recall_lr, f1_lr, roc_auc_lr]
rf_metrics = [accuracy_rf, precision_rf, recall_rf, f1_rf, roc_auc_rf]
knn_metrics = [accuracy_knn, precision_knn, recall_knn, f1_knn, roc_auc_knn]

# Gráfico de Barras Comparativo
plt.figure(figsize=(10, 6))
bar_width = 0.2
index = range(len(metrics))
plt.bar(index, lr_metrics, bar_width, label='Logistic Regression', color='b')
plt.bar([i + bar_width for i in index], rf_metrics, bar_width, label='Random Forest', color='g')
plt.bar([i + 2 * bar_width for i in index], knn_metrics, bar_width, label='K-NN', color='r')
plt.xlabel('Metrics')
plt.ylabel('Score')
plt.title('Performance Metrics Comparison')
plt.xticks([i + bar_width for i in index], metrics)
plt.legend()
plt.show()

# Curvas ROC
plt.figure(figsize=(8, 8))
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)
fpr_knn, tpr_knn, _ = roc_curve(y_test, y_pred_knn)
plt.plot(fpr_lr, tpr_lr, label='Logistic Regression')
plt.plot(fpr_rf, tpr_rf, label='Random Forest')
plt.plot(fpr_knn, tpr_knn, label='K-NN')
plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()